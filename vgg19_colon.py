# -*- coding: utf-8 -*-
"""VGG19_colon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Jaz0UIcTrCj0aU7hXPlVH-xDsMA37N7
"""

import os
import shutil

from google.colab import drive
drive.mount('/content/drive')

train_path = '/content/drive/My Drive/Colon/4x/train'
valid_path = '/content/drive/My Drive/Colon/4x/valid_0.1'

model_path = '/content/drive/My Drive/Colon/model_4x_vgg19/'

valid_pos = os.listdir('/content/drive/My Drive/Colon/4x/valid_0.1/positive/')
valid_neg = os.listdir('/content/drive/My Drive/Colon/4x/valid_0.1/negative/')

train_pos = os.listdir('/content/drive/My Drive/Colon/4x/train/positive/')
train_neg = os.listdir('/content/drive/My Drive/Colon/4x/train/negative/')

print('train:', len(train_pos), len(train_neg))
print('valid:', len(valid_pos), len(valid_neg))

# import the needed packages
import matplotlib.pyplot as plt
import matplotlib.image as img
import tensorflow.keras as keras
import numpy as np

from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size = 30

def generators(shape, preprocessing): 
    '''Create the training and validation datasets for 
    a given image shape.
    '''
    imgdatagen = ImageDataGenerator(
        preprocessing_function = preprocessing,
        horizontal_flip = True, 
        validation_split = 0.1,
    )

    height, width = shape

    train_dataset = imgdatagen.flow_from_directory(
        train_path,
        target_size = (height, width), 
        classes = ('positive','negative'),
        batch_size = batch_size,
        subset = 'training', 
    )

    val_dataset = imgdatagen.flow_from_directory(
        train_path,
        target_size = (height, width), 
        classes = ('positive','negative'),
        batch_size = batch_size,
        subset = 'validation'
    )
    return train_dataset, val_dataset

vgg19 = keras.applications.vgg19
conv_model = vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))
for layer in conv_model.layers: 
    layer.trainable = False
x = keras.layers.Flatten()(conv_model.output)
x = keras.layers.Dense(100, activation='relu')(x)
x = keras.layers.Dense(100, activation='relu')(x)
x = keras.layers.Dense(100, activation='relu')(x)
predictions = keras.layers.Dense(2, activation='softmax')(x)
full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)
full_model.summary()

train_dataset, val_dataset = generators((224,224), preprocessing=vgg19.preprocess_input)

from datetime import datetime

save_path = model_path + "saved-model-{epoch:02d}-{val_acc:.2f}.hdf5"
checkpoint = keras.callbacks.ModelCheckpoint(
    save_path, 
    monitor='val_acc', 
    verbose=1, 
    save_best_only=False, 
    mode='max'
    )
callbacks = [checkpoint]
start = datetime.now()

full_model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.Adamax(lr=0.001),
                  metrics=['acc'])
history = full_model.fit(
    train_dataset, 
    validation_data = val_dataset,
    workers=10,
    epochs=10,
    callbacks = callbacks
)

loaded_model = keras.models.load_model(model_path + 'saved-model-02-0.86.hdf5')
score = loaded_model.evaluate(val_dataset)

print('Test Loss:', score[0])
print('Test accuracy:', score[1])

# Evaluating our model on test data set
score = full_model.evaluate(val_dataset)
print('Test Loss:', score[0])
print('Test accuracy:', score[1])

# Visualization
import matplotlib.pyplot as plt
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Accuracy','Validation Accuracy','loss','Validation Loss'])
plt.show()