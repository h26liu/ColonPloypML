# -*- coding: utf-8 -*-
"""transfer_learning_vgg16_colon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VN9HoAz9vVdPFzAMQ3VtDLmFtVuZCCKH
"""

import os
import shutil

from google.colab import drive
drive.mount('/content/drive')

train_path = '/content/drive/My Drive/Colon/4x/train'
valid_path = '/content/drive/My Drive/Colon/4x/valid_0.1'

model_path = '/content/drive/My Drive/Colon/model_4x/'

valid_pos = os.listdir('/content/drive/My Drive/Colon/4x/valid_0.1/positive/')
valid_neg = os.listdir('/content/drive/My Drive/Colon/4x/valid_0.1/negative/')

train_pos = os.listdir('/content/drive/My Drive/Colon/4x/train/positive/')
train_neg = os.listdir('/content/drive/My Drive/Colon/4x/train/negative/')

print('train:', len(train_pos), len(train_neg))
print('valid:', len(valid_pos), len(valid_neg))

# import the needed packages
import matplotlib.pyplot as plt
import matplotlib.image as img
import tensorflow.keras as keras
import numpy as np

from tensorflow.keras.preprocessing.image import ImageDataGenerator

batch_size = 30

def generators(shape, preprocessing): 
    '''Create the training and validation datasets for 
    a given image shape.
    '''
    imgdatagen = ImageDataGenerator(
        preprocessing_function = preprocessing,
        horizontal_flip = True, 
        validation_split = 0.2,
    )

    height, width = shape

    train_dataset = imgdatagen.flow_from_directory(
        train_path,
        target_size = (height, width), 
        classes = ('positive','negative'),
        batch_size = batch_size,
        subset = 'training', 
    )

    val_dataset = imgdatagen.flow_from_directory(
        train_path,
        target_size = (height, width), 
        classes = ('positive','negative'),
        batch_size = batch_size,
        subset = 'validation'
    )
    return train_dataset, val_dataset

def plot_history(history, yrange):
    '''Plot loss and accuracy as a function of the epoch,
    for the training and validation datasets.
    '''
    acc = history.history['acc']
    val_acc = history.history['val_acc']
    loss = history.history['loss']
    val_loss = history.history['val_loss']

    # Get number of epochs
    epochs = range(len(acc))

    # Plot training and validation accuracy per epoch
    plt.plot(epochs, acc)
    plt.plot(epochs, val_acc)
    plt.title('Training and validation accuracy')
    plt.ylim(yrange)
    
    # Plot training and validation loss per epoch
    plt.figure()

    plt.plot(epochs, loss)
    plt.plot(epochs, val_loss)
    plt.title('Training and validation loss')
    
    plt.show()

vgg16 = keras.applications.vgg16
vgg = vgg16.VGG16(weights='imagenet')
vgg.summary()

vgg16 = keras.applications.vgg16
conv_model = vgg16.VGG16(weights='imagenet', include_top=False)
conv_model.summary()

train_dataset, val_dataset = generators((224,224), preprocessing=vgg16.preprocess_input)

conv_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))

# flatten the output of the convolutional part: 
x = keras.layers.Flatten()(conv_model.output)
# three hidden layers
x = keras.layers.Dense(100, activation='relu')(x)
x = keras.layers.Dense(100, activation='relu')(x)
x = keras.layers.Dense(100, activation='relu')(x)
# final softmax layer with two categories (dog and cat)
predictions = keras.layers.Dense(2, activation='softmax')(x)

# creating the full model:
full_model = keras.models.Model(inputs=conv_model.input, outputs=predictions)
full_model.summary()

for layer in conv_model.layers:
    layer.trainable = False

full_model.summary()

2508900+10100*2+202

from datetime import datetime

save_path = model_path + "saved-model-{epoch:02d}-{val_acc:.2f}.hdf5"
checkpoint = keras.callbacks.ModelCheckpoint(
    save_path, 
    monitor='val_acc', 
    verbose=1, 
    save_best_only=False, 
    mode='max'
    )
callbacks = [checkpoint]
start = datetime.now()

full_model.compile(loss='binary_crossentropy',
                  optimizer=keras.optimizers.Adamax(lr=0.001),
                  metrics=['acc'])
history = full_model.fit_generator(
    train_dataset, 
    validation_data = val_dataset,
    workers=10,
    epochs=10,
    callbacks = callbacks
)

# Evaluating our model on test data set
score = full_model.evaluate(val_dataset)
print('Test Loss:', score[0])
print('Test accuracy:', score[1])

# Visualization
import matplotlib.pyplot as plt
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Accuracy','Validation Accuracy','loss','Validation Loss'])
plt.show()